%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Quatix at 2021-10-28 13:50:55 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@article{cite-key,
	date-added = {2021-10-28 13:49:54 -0400},
	date-modified = {2021-10-28 13:49:54 -0400},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAqLi4vLi4vLi4vRG93bmxvYWRzL2FjbV8yNjQxMTkwLjI2NDExOTguYmliTxEBXgAAAAABXgACAAAFRElTQ08AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEJEAAH/////F2FjbV8yNjQxMTkwLjI2NDExOTguYmliAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP////8AAAAAAAAAAAAAAAAAAwACAAAKIGN1AAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAAAIAMC86VXNlcnM6cXVhdGl4OkRvd25sb2FkczphY21fMjY0MTE5MC4yNjQxMTk4LmJpYgAOADAAFwBhAGMAbQBfADIANgA0ADEAMQA5ADAALgAyADYANAAxADEAOQA4AC4AYgBpAGIADwAMAAUARABJAFMAQwBPABIALlVzZXJzL3F1YXRpeC9Eb3dubG9hZHMvYWNtXzI2NDExOTAuMjY0MTE5OC5iaWIAEwABLwAAFQACAA3//wAAAAgADQAaACQAUQAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAGz}}

@article{baker2016designing,
	author = {Baker, Bowen and Gupta, Otkrist and Naik, Nikhil and Raskar, Ramesh},
	journal = {arXiv preprint arXiv:1611.02167},
	title = {Designing neural network architectures using reinforcement learning},
	year = {2016}}

@inproceedings{bergstra2013hyperopt,
	author = {Bergstra, James and Yamins, Dan and Cox, David D and others},
	booktitle = {Proceedings of the 12th Python in science conference},
	organization = {Citeseer},
	pages = {20},
	title = {Hyperopt: A python library for optimizing the hyperparameters of machine learning algorithms},
	volume = {13},
	year = {2013}}

@article{bischl2016aslib,
	author = {Bischl, Bernd and Kerschke, Pascal and Kotthoff, Lars and Lindauer, Marius and Malitsky, Yuri and Fr{\'e}chette, Alexandre and Hoos, Holger and Hutter, Frank and Leyton-Brown, Kevin and Tierney, Kevin and others},
	journal = {Artificial Intelligence},
	pages = {41--58},
	publisher = {Elsevier},
	title = {Aslib: A benchmark library for algorithm selection},
	volume = {237},
	year = {2016}}

@inproceedings{de2017recipe,
	author = {de S{\'a}, Alex GC and Pinto, Walter Jos{\'e} GS and Oliveira, Luiz Otavio VB and Pappa, Gisele L},
	booktitle = {European Conference on Genetic Programming},
	organization = {Springer},
	pages = {246--261},
	title = {RECIPE: a grammar-based framework for automatically evolving classification pipelines},
	year = {2017}}

@inproceedings{de2018automated,
	author = {de S{\'a}, Alex GC and Freitas, Alex A and Pappa, Gisele L},
	booktitle = {International Conference on Parallel Problem Solving from Nature},
	organization = {Springer},
	pages = {308--320},
	title = {Automated selection and configuration of multi-label classification algorithms with grammar-based genetic programming},
	year = {2018}}

@article{elshawi2019automated,
	author = {Elshawi, Radwa and Maher, Mohamed and Sakr, Sherif},
	journal = {arXiv preprint arXiv:1906.02287},
	title = {Automated machine learning: State-of-the-art and open challenges},
	year = {2019}}

@inproceedings{jin2019auto,
	author = {Jin, Haifeng and Song, Qingquan and Hu, Xia},
	booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
	pages = {1946--1956},
	title = {Auto-keras: An efficient neural architecture search system},
	year = {2019}}

@inproceedings{komer2014hyperopt,
	author = {Komer, Brent and Bergstra, James and Eliasmith, Chris},
	booktitle = {ICML workshop on AutoML},
	organization = {Citeseer},
	pages = {50},
	title = {Hyperopt-sklearn: automatic hyperparameter configuration for scikit-learn},
	volume = {9},
	year = {2014}}

@inproceedings{maher2019smartml,
	author = {Maher, Mohamed and Sakr, Sherif},
	booktitle = {EDBT: 22nd International Conference on Extending Database Technology},
	title = {Smartml: A meta learning-based framework for automated selection and hyperparameter tuning for machine learning algorithms},
	year = {2019}}

@inproceedings{mendoza2016towards,
	author = {Mendoza, Hector and Klein, Aaron and Feurer, Matthias and Springenberg, Jost Tobias and Hutter, Frank},
	booktitle = {Workshop on Automatic Machine Learning},
	organization = {PMLR},
	pages = {58--65},
	title = {Towards automatically-tuned neural networks},
	year = {2016}}

@article{mohr2018ml,
	author = {Mohr, Felix and Wever, Marcel and H{\"u}llermeier, Eyke},
	journal = {Machine Learning},
	number = {8},
	pages = {1495--1515},
	publisher = {Springer},
	title = {ML-Plan: Automated machine learning via hierarchical planning},
	volume = {107},
	year = {2018}}

@inproceedings{fusi2018advances,
	author = {Fusi, Nicolo and Sheth, Rishit and Elibol, Melih},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Probabilistic Matrix Factorization for Automated Machine Learning},
	url = {https://proceedings.neurips.cc/paper/2018/file/b59a51a3c0bf9c5228fde841714f523a-Paper.pdf},
	volume = {31},
	year = {2018},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2018/file/b59a51a3c0bf9c5228fde841714f523a-Paper.pdf}}

@article{yang2018oboe,
	archiveprefix = {arXiv},
	author = {Chengrun Yang and Yuji Akimoto and Dae Won Kim and Madeleine Udell},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1808-03233.bib},
	eprint = {1808.03233},
	journal = {CoRR},
	timestamp = {Sun, 02 Sep 2018 15:01:57 +0200},
	title = {{OBOE:} Collaborative Filtering for AutoML Initialization},
	url = {http://arxiv.org/abs/1808.03233},
	volume = {abs/1808.03233},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1808.03233}}

@inproceedings{olson2016evaluation,
	author = {Olson, Randal S and Bartley, Nathan and Urbanowicz, Ryan J and Moore, Jason H},
	booktitle = {Proceedings of the genetic and evolutionary computation conference 2016},
	pages = {485--492},
	title = {Evaluation of a tree-based pipeline optimization tool for automating data science},
	year = {2016}}

@inproceedings{pham2018efficient,
	author = {Pham, Hieu and Guan, Melody and Zoph, Barret and Le, Quoc and Dean, Jeff},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {4095--4104},
	title = {Efficient neural architecture search via parameters sharing},
	year = {2018}}

@article{rakotoarison2019automated,
	author = {Rakotoarison, Herilalaina and Schoenauer, Marc and Sebag, Mich{\`e}le},
	journal = {arXiv preprint arXiv:1906.00170},
	title = {Automated machine learning with Monte-Carlo Tree Search},
	year = {2019}}

@inproceedings{evans2020adaptive,
	author = {Evans, Benjamin and Xue, Bing and Zhang, Mengjie},
	booktitle = {2020 IEEE Congress on Evolutionary Computation (CEC)},
	organization = {IEEE},
	pages = {1--8},
	title = {An adaptive and near parameter-free evolutionary computation approach towards true automation in automl},
	year = {2020}}

@inproceedings{shang2019democratizing,
	author = {Shang, Zeyuan and Zgraggen, Emanuel and Buratti, Benedetto and Kossmann, Ferdinand and Eichmann, Philipp and Chung, Yeounoh and Binnig, Carsten and Upfal, Eli and Kraska, Tim},
	booktitle = {Proceedings of the 2019 International Conference on Management of Data},
	pages = {1171--1188},
	title = {Democratizing data science through interactive curation of ml pipelines},
	year = {2019}}

@inproceedings{thornton2013auto,
	author = {Thornton, Chris and Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
	booktitle = {Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining},
	pages = {847--855},
	title = {Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms},
	year = {2013}}

@article{wang2018rafiki,
	author = {Wang, Wei and Wang, Sheng and Gao, Jinyang and Zhang, Meihui and Chen, Gang and Ng, Teck Khim and Ooi, Beng Chin},
	journal = {arXiv preprint arXiv:1804.06087},
	title = {Rafiki: Machine learning as an analytics service system},
	year = {2018}}

@article{wang2021flaml,
	author = {Wang, Chi and Wu, Qingyun and Weimer, Markus and Zhu, Erkang},
	journal = {Proceedings of Machine Learning and Systems},
	title = {FLAML: A Fast and Lightweight AutoML Library},
	volume = {3},
	year = {2021}}

@article{zoph2016neural,
	author = {Zoph, Barret and Le, Quoc V},
	journal = {arXiv preprint arXiv:1611.01578},
	title = {Neural architecture search with reinforcement learning},
	year = {2016}}

@inproceedings{swearingen2017atm,
	author = {Swearingen, Thomas and Drevo, Will and Cyphers, Bennett and Cuesta-Infante, Alfredo and Ross, Arun and Veeramachaneni, Kalyan},
	booktitle = {2017 IEEE International Conference on Big Data (Big Data)},
	organization = {IEEE},
	pages = {151--162},
	title = {ATM: A distributed, collaborative, scalable system for automated machine learning},
	year = {2017}}

@inproceedings{yang2020automl,
	author = {Yang, Chengrun and Fan, Jicong and Wu, Ziyang and Udell, Madeleine},
	booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
	pages = {1446--1456},
	title = {Automl pipeline selection: Efficiently navigating the combinatorial space},
	year = {2020}}

@article{zimmer2021auto,
	author = {Zimmer, Lucas and Lindauer, Marius and Hutter, Frank},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	publisher = {IEEE},
	title = {Auto-Pytorch: Multi-Fidelity MetaLearning for Robust AutoDL},
	year = {2021}}

@inproceedings{drori2018alphad3m,
	author = {Drori, Iddo and Krishnamurthy, Yamuna and Rampin, Remi and Louren{\c{c}}o, Raoni and One, Jorge and Cho, Kyunghyun and Silva, Claudio and Freire, Juliana},
	booktitle = {AutoML Workshop at ICML},
	title = {AlphaD3M: Machine learning pipeline synthesis},
	year = {2018}}

@inproceedings{fuerer2015efficient,
	author = {Feurer, Matthias and Klein, Aaron and Eggensperger, Katharina and Springenberg, Jost and Blum, Manuel and Hutter, Frank},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Efficient and Robust Automated Machine Learning},
	url = {https://proceedings.neurips.cc/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf},
	volume = {28},
	year = {2015},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf}}

@inbook{olson2019tpot,
	abstract = {As data science becomes increasingly mainstream, there will be an ever-growing demand for data science tools that are more accessible, flexible, and scalable. In response to this demand, automated machine learning (AutoML) researchers have begun building systems that automate the process of designing and optimizing machine learning pipelines. In this chapter we present TPOT v0.3, an open source genetic programming-based AutoML system that optimizes a series of feature preprocessors and machine learning models with the goal of maximizing classification accuracy on a supervised classification task. We benchmark TPOT on a series of 150 supervised classification tasks and find that it significantly outperforms a basic machine learning analysis in 21 of them, while experiencing minimal degradation in accuracy on 4 of the benchmarks---all without any domain knowledge nor human input. As such, genetic programming-based AutoML systems show considerable promise in the AutoML domain.},
	address = {Cham},
	author = {Olson, Randal S. and Moore, Jason H.},
	booktitle = {Automated Machine Learning: Methods, Systems, Challenges},
	doi = {10.1007/978-3-030-05318-5_8},
	isbn = {978-3-030-05318-5},
	pages = {151--160},
	publisher = {Springer International Publishing},
	title = {TPOT: A Tree-Based Pipeline Optimization Tool for Automating Machine Learning},
	url = {https://doi.org/10.1007/978-3-030-05318-5_8},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-030-05318-5_8}}

@inproceedings{chen2018autostacker,
	abstract = {In this work, an automatic machine learning (AutoML) modeling architecture called
	Autostacker is introduced. Autostacker combines an innovative hierarchical stacking
	architecture and an evolutionary algorithm (EA) to perform efficient parameter search
	without the need for prior domain knowledge about the data or feature preprocessing.
	Using EA, Autostacker quickly evolves candidate pipelines with high predictive accuracy.
	These pipelines can be used in their given form, or serve as a starting point for
	further augmentation and refinement by human experts. Autostacker finds innovative
	machine learning model combinations and structures, rather than selecting a single
	model and optimizing its hyperparameters. When its performance on fifteen datasets
	is compared with that of other AutoML systems, Autostacker produces superior or competitive
	results in terms of both test accuracy and time cost.},
	address = {New York, NY, USA},
	author = {Chen, Boyuan and Wu, Harvey and Mo, Warren and Chattopadhyay, Ishanu and Lipson, Hod},
	booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
	doi = {10.1145/3205455.3205586},
	isbn = {9781450356183},
	keywords = {autoML, evolutionary machine learning, machine learning},
	location = {Kyoto, Japan},
	numpages = {8},
	pages = {402--409},
	publisher = {Association for Computing Machinery},
	series = {GECCO '18},
	title = {Autostacker: A Compositional Evolutionary Learning System},
	url = {https://doi.org/10.1145/3205455.3205586},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1145/3205455.3205586}}

@inproceedings{real2020automl,
	author = {Real, Esteban and Liang, Chen and So, David and Le, Quoc},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {8007--8019},
	title = {Automl-zero: Evolving machine learning algorithms from scratch},
	year = {2020}}

@article{NSGA-II,
	abstract = {Multi-objective evolutionary algorithms (MOEAs) that use non-dominated sorting and
	sharing have been criticized mainly for: (1) their O(MN3) computational complexity
	(where M is the number of objectives and N is the population size); (2) their non-elitism
	approach; and (3) the need to specify a sharing parameter. In this paper, we suggest
	a non-dominated sorting-based MOEA, called NSGA-II (Non-dominated Sorting Genetic
	Algorithm II), which alleviates all of the above three difficulties. Specifically,
	a fast non-dominated sorting approach with O(MN2) computational complexity is presented.
	Also, a selection operator is presented that creates a mating pool by combining the
	parent and offspring populations and selecting the best N solutions (with respect
	to fitness and spread). Simulation results on difficult test problems show that NSGA-II
	is able, for most problems, to find a much better spread of solutions and better convergence
	near the true Pareto-optimal front compared to the Pareto-archived evolution strategy
	and the strength-Pareto evolutionary algorithm - two other elitist MOEAs that pay
	special attention to creating a diverse Pareto-optimal front. Moreover, we modify
	the definition of dominance in order to solve constrained multi-objective problems
	efficiently. Simulation results of the constrained NSGA-II on a number of test problems,
	including a five-objective, seven-constraint nonlinear problem, are compared with
	another constrained multi-objective optimizer, and the much better performance of
	NSGA-II is observed},
	author = {Deb, K. and Pratap, A. and Agarwal, S. and Meyarivan, T.},
	doi = {10.1109/4235.996017},
	issn = {1089-778X},
	issue_date = {April 2002},
	journal = {Trans. Evol. Comp},
	month = apr,
	number = {2},
	numpages = {16},
	pages = {182--197},
	publisher = {IEEE Press},
	title = {A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II},
	url = {https://doi.org/10.1109/4235.996017},
	volume = {6},
	year = {2002},
	Bdsk-Url-1 = {https://doi.org/10.1109/4235.996017}}

@article{alphazero,
	author = {David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy P. Lillicrap and Karen Simonyan and Demis Hassabis},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1712-01815.bib},
	eprint = {1712.01815},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:46:01 +0200},
	title = {Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm},
	url = {http://arxiv.org/abs/1712.01815},
	volume = {abs/1712.01815},
	year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1712.01815}}

@article{OracleAutoML,
	abstract = {Machine learning (ML) is at the forefront of the rising popularity of data-driven
	software applications. The resulting rapid proliferation of ML technology, explosive
	data growth, and shortage of data science expertise have caused the industry to face
	increasingly challenging demands to keep up with fast-paced develop-and-deploy model
	lifecycles. Recent academic and industrial research efforts have started to address
	this problem through automated machine learning (AutoML) pipelines and have focused
	on model performance as the first-order design objective. We present Oracle AutoML,
	a novel iteration-free AutoML pipeline designed to not only provide accurate models,
	but also in a shorter runtime. We are able to achieve these objectives by eliminating
	the need to continuously iterate over various pipeline configurations. In our feed-forward
	approach, each pipeline stage makes decisions based on metalearned proxy models that
	can predict candidate pipeline configuration performances before building the full
	final model. Our approach, which builds and tunes only the best candidate pipeline,
	achieves better scores at a fraction of the time compared to state-of-the-art open
	source AutoML tools, such as H2O and Auto-sklearn. This makes Oracle AutoML a prime
	candidate for addressing current industry challenges.},
	author = {Yakovlev, Anatoly and Moghadam, Hesam Fathi and Moharrer, Ali and Cai, Jingxiao and Chavoshi, Nikan and Varadarajan, Venkatanathan and Agrawal, Sandeep R. and Idicula, Sam and Karnagel, Tomas and Jinturkar, Sanjay and Agarwal, Nipun},
	doi = {10.14778/3415478.3415542},
	issn = {2150-8097},
	issue_date = {August 2020},
	journal = {Proc. VLDB Endow.},
	month = aug,
	number = {12},
	numpages = {15},
	pages = {3166--3180},
	publisher = {VLDB Endowment},
	title = {Oracle AutoML: A Fast and Predictive AutoML Pipeline},
	url = {https://doi.org/10.14778/3415478.3415542},
	volume = {13},
	year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.14778/3415478.3415542}}

@article{sun2013pairwise,
	author = {Sun, Quan and Pfahringer, Bernhard},
	journal = {Machine learning},
	number = {1},
	pages = {141--161},
	publisher = {Springer},
	title = {Pairwise meta-rules for better meta-learning-based algorithm ranking},
	volume = {93},
	year = {2013}}

@inproceedings{Pinto2016TowardsAG,
	author = {F{\'a}bio Pinto and C. Soares and Jo{\~a}o Mendes-Moreira},
	booktitle = {PAKDD},
	title = {Towards Automatic Generation of Metafeatures},
	year = {2016}}

@inproceedings{pinto2014framework,
	abstract = {This paper proposes a framework to decompose and develop metafeatures for Metalearning
	(MtL) problems. Several metafeatures (also known as data characteristics) are proposed
	in the literature for a wide range of problems. Since MtL applicability is very general
	but problem dependent, researchers focus on generating specific and yet informative
	metafeatures for each problem. This process is carried without any sort of conceptual
	framework. We believe that such framework would open new horizons on the development
	of metafeatures and also aid the process of understanding the metafeatures already
	proposed in the state-of-the-art. We propose a framework with the aim of fill that
	gap and we show its applicability in a scenario of algorithm recommendation for regression
	problems.},
	address = {Aachen, DEU},
	author = {Pinto, F\'{a}bio and Soares, Carlos and Mendes-Moreira, Jo\~{a}o},
	booktitle = {Proceedings of the 2014 International Conference on Meta-Learning and Algorithm Selection - Volume 1201},
	isbn = {16130073},
	location = {Prague, Czech Republic},
	numpages = {5},
	pages = {32--36},
	publisher = {CEUR-WS.org},
	series = {MLAS'14},
	title = {A Framework to Decompose and Develop Metafeatures},
	year = {2014}}

@article{bilalli2017predictive,
	abstract = {Abstract The demand for performing data analysis is steadily rising. As a consequence,
	people of different profiles i.e., nonexperienced users have started to analyze their
	data. However, this is challenging for them. A key step that poses difficulties and
	determines the success of the analysis is data mining model/algorithm selection problem.
	Meta-learning is a technique used for assisting non-expert users in this step. The
	effectiveness of meta-learning is, however, largely dependent on the description/characterization
	of datasets i.e., meta-features used for meta-learning. There is a need for improving
	the effectiveness of meta-learning by identifying and designing more predictive meta-features.
	In this work, we use a method from exploratory factor analysis to study the predictive
	power of different meta-features collected in OpenML, which is a collaborative machine
	learning platform that is designed to store and organize meta-data about datasets,
	data mining algorithms, models and their evaluations. We first use the method to extract
	latent features, which are abstract concepts that group together meta-features with
	common characteristics. Then, we study and visualize the relationship of the latent
	features with three different performance measures of four classification algorithms
	on hundreds of datasets available in OpenML, and we select the latent features with
	the highest predictive power. Finally, we use the selected latent features to perform
	meta-learning and we show that our method improves the meta-learning process. Furthermore,
	we design an easy to use application for retrieving different meta-data from OpenML
	as the biggest source of data in this domain.},
	address = {USA},
	author = {Bilalli, Besim and Abell\'{o}, Alberto and Aluja-Banet, Tom\'{\i}s},
	doi = {10.1515/amcs-2017-0048},
	issn = {1641-876X},
	issue_date = {20 12 2017},
	journal = {Int. J. Appl. Math. Comput. Sci.},
	keywords = {feature extraction, meta-learning, feature selection},
	month = dec,
	number = {4},
	numpages = {16},
	pages = {697--712},
	publisher = {Walter de Gruyter &amp; Co.},
	title = {On the Predictive Power of Meta-Features in OpenML},
	url = {https://doi.org/10.1515/amcs-2017-0048},
	volume = {27},
	year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1515/amcs-2017-0048}}

@article{Rivolli2018TowardsRE,
	author = {Adriano Rivolli and L. P. F. Garcia and Carlos Soares and J. Vanschoren and A. Carvalho},
	journal = {ArXiv},
	title = {Towards Reproducible Empirical Research in Meta-Learning},
	volume = {abs/1808.10406},
	year = {2018}}

@inproceedings{santos2004selection,
	author = {Santos, Patr{\'\i}cia and Ludermir, Teresa and Prud{\^e}ncio, Ricardo},
	doi = {10.1109/ICHIS.2004.86},
	journal = {Proceedings - HIS'04: 4th International Conference on Hybrid Intelligent Systems},
	month = {01},
	pages = {366-371},
	title = {Selection of Time Series Forecasting Models based on Performance Information},
	year = {2004},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICHIS.2004.86}}

@article{bradzil2003ranking,
	author = {Brazdil, Pavel and Soares, Carlos and Costa, Joaquim},
	doi = {10.1023/A:1021713901879},
	journal = {Machine Learning},
	month = {03},
	pages = {251-277},
	title = {Ranking Learning Algorithms: Using IBL and Meta-Learning on Accuracy and Time Results},
	volume = {50},
	year = {2003},
	Bdsk-Url-1 = {https://doi.org/10.1023/A:1021713901879}}

@inproceedings{todorovski2002ranking,
	author = {Todorovski, Ljupco and Blockeel, Hendrik and D{\v z}eroski, Sa{\v s}o},
	doi = {10.1007/3-540-36755-1_37},
	isbn = {978-3-540-44036-9},
	month = {08},
	pages = {444-455},
	title = {Ranking with Predictive Clustering Trees},
	volume = {2430},
	year = {2002},
	Bdsk-Url-1 = {https://doi.org/10.1007/3-540-36755-1_37}}

@article{tomaz2020oblique,
	author = {Tomaz Stepisnik and Dragi Kocev},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-2007-13617.bib},
	eprint = {2007.13617},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Wed, 29 Jul 2020 15:36:39 +0200},
	title = {Oblique Predictive Clustering Trees},
	url = {https://arxiv.org/abs/2007.13617},
	volume = {abs/2007.13617},
	year = {2020},
	Bdsk-Url-1 = {https://arxiv.org/abs/2007.13617}}

@inproceedings{guerra2008predicting,
	author = {Guerra, Silvio and Prudencio, Ricardo and Ludermir, Teresa},
	doi = {10.1007/978-3-540-87536-9_54},
	isbn = {978-3-540-87535-2},
	month = {09},
	pages = {523-532},
	title = {Predicting the Performance of Learning Algorithms Using Support Vector Machines as Meta-regressors},
	volume = {5163},
	year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-540-87536-9_54}}

@article{reif2012automatic,
	author = {Reif, Matthias and Shafait, Faisal and Goldstein, Markus and Breuel, Thomas and Dengel, Andreas},
	doi = {10.1007/s10044-012-0280-z},
	journal = {Pattern Analysis and Applications},
	month = {02},
	title = {Automatic Classifier Selection for Non-Experts},
	volume = {17},
	year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10044-012-0280-z}}

@inproceedings{ridd2014using,
	abstract = {Work on metalearning for algorithm selection has often been criticized because it
	mostly considers only the default parameter settings of the candidate base learning
	algorithms. Many have indeed argued that the choice of parameter values can have a
	significant impact on accuracy. Yet little empirical evidence exists to provide definitive
	support for that argument. Recent experiments do suggest that parameter optimization
	may indeed have an impact. However, the distribution of performance differences has
	a long tail, suggesting that in most cases parameter optimization has little effect
	on accuracy. In this paper, we revisit some of these results and use metalearning
	to characterize the situations when parameter optimization is likely to cause a significant
	increase in accuracy. In so doing, we show that 1) a relatively simple and efficient
	landmarker carries significant predictive power, and 2) metalearning for algorithm
	selection should be effected in two phases, the first in which one determines whether
	parameter optimization is likely to increase accuracy, and the second in which algorithm
	selection actually takes place.},
	address = {Aachen, DEU},
	author = {Ridd, Parker and Giraud-Carrier, Christophe},
	booktitle = {Proceedings of the 2014 International Conference on Meta-Learning and Algorithm Selection - Volume 1201},
	isbn = {16130073},
	location = {Prague, Czech Republic},
	numpages = {6},
	pages = {18--23},
	publisher = {CEUR-WS.org},
	series = {MLAS'14},
	title = {Using Metalearning to Predict When Parameter Optimization is Likely to Improve Classification Accuracy},
	year = {2014}}

@inproceedings{sanders2017informing,
	author = {Sanders, Samantha and Giraud-Carrier, Christophe},
	doi = {10.1109/ICDM.2017.137},
	month = {11},
	pages = {1051-1056},
	title = {Informing the Use of Hyperparameter Optimization Through Metalearning},
	year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICDM.2017.137}}

@inproceedings{leite2017selecting,
	author = {Leite, Rui and Brazdil, Pavel and Vanschoren, Joaquin},
	doi = {10.1007/978-3-642-31537-4_10},
	isbn = {978-3-642-31536-7},
	journal = {Lecture Notes in Computer Science},
	month = {07},
	pages = {117-131},
	title = {Selecting Classification Algorithms with Active Testing},
	volume = {7376},
	year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-642-31537-4_10}}

@article{abdulrahman2018speeding,
	abstract = {Algorithm selection methods can be speeded-up substantially by incorporating multi-objective
	measures that give preference to algorithms that are both promising and fast to evaluate.
	In this paper, we introduce such a measure, A3R, and incorporate it into two algorithm
	selection techniques: average ranking and active testing. Average ranking combines
	algorithm rankings observed on prior datasets to identify the best algorithms for
	a new dataset. The aim of the second method is to iteratively select algorithms to
	be tested on the new dataset, learning from each new evaluation to intelligently select
	the next best candidate. We show how both methods can be upgraded to incorporate a
	multi-objective measure A3R that combines accuracy and runtime. It is necessary to
	establish the correct balance between accuracy and runtime, as otherwise time will
	be wasted by conducting less informative tests. The correct balance can be set by
	an appropriate parameter setting within function A3R that trades off accuracy and
	runtime. Our results demonstrate that the upgraded versions of Average Ranking and
	Active Testing lead to much better mean interval loss values than their accuracy-based
	counterparts.},
	address = {USA},
	author = {Abdulrahman, Salisu Mamman and Brazdil, Pavel and Rijn, Jan N. and Vanschoren, Joaquin},
	doi = {10.1007/s10994-017-5687-8},
	issn = {0885-6125},
	issue_date = {January 2018},
	journal = {Mach. Learn.},
	keywords = {Loss curves, Meta-learning, Average ranking, Algorithm selection, Mean interval loss, Ranking of algorithms, Active testing},
	month = jan,
	number = {1},
	numpages = {30},
	pages = {79--108},
	publisher = {Kluwer Academic Publishers},
	title = {Speeding up Algorithm Selection Using Average Ranking and Active Testing by Introducing Runtime},
	url = {https://doi.org/10.1007/s10994-017-5687-8},
	volume = {107},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10994-017-5687-8}}

@inproceedings{witsuba2015learning,
	author = {Wistuba, Martin and Schilling, Nicolas and Schmidt-Thieme, Lars},
	booktitle = {2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)},
	doi = {10.1109/DSAA.2015.7344817},
	pages = {1-10},
	title = {Learning hyperparameter optimization initializations},
	year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1109/DSAA.2015.7344817}}

@article{abdulrahman2014measures,
	author = {Abdulrahman, Salisu and Brazdil, Pavel},
	journal = {CEUR Workshop Proceedings},
	month = {01},
	pages = {49-50},
	title = {Measures for combining accuracy and time for meta-learning},
	volume = {1201},
	year = {2014}}

@inproceedings{rijn2018hyp,
	abstract = {With the advent of automated machine learning, automated hyperparameter optimization
	methods are by now routinely used in data mining. However, this progress is not yet
	matched by equal progress on automatic analyses that yield information beyond performance-optimizing
	hyperparameter settings. In this work, we aim to answer the following two questions:
	Given an algorithm, what are generally its most important hyperparameters, and what
	are typically good values for these? We present methodology and a framework to answer
	these questions based on meta-learning across many datasets. We apply this methodology
	using the experimental meta-data available on OpenML to determine the most important
	hyperparameters of support vector machines, random forests and Adaboost, and to infer
	priors for all their hyperparameters. The results, obtained fully automatically, provide
	a quantitative basis to focus efforts in both manual algorithm design and in automated
	hyperparameter optimization. The conducted experiments confirm that the hyperparameters
	selected by the proposed method are indeed the most important ones and that the obtained
	priors also lead to statistically significant improvements in hyperparameter optimization.},
	address = {New York, NY, USA},
	author = {van Rijn, Jan N. and Hutter, Frank},
	booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery},
	doi = {10.1145/3219819.3220058},
	isbn = {9781450355520},
	keywords = {meta-learning, hyperparameter importance, hyperparameter optimization},
	location = {London, United Kingdom},
	numpages = {10},
	pages = {2367--2376},
	publisher = {Association for Computing Machinery},
	series = {KDD '18},
	title = {Hyperparameter Importance Across Datasets},
	url = {https://doi.org/10.1145/3219819.3220058},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1145/3219819.3220058}}

@inproceedings{witsuba2015hyper,
	author = {Wistuba, Martin and Schilling, Nicolas and Schmidt-Thieme, Lars},
	doi = {10.1007/978-3-319-23525-7_7},
	month = {09},
	pages = {104-119},
	title = {Hyperparameter Search Space Pruning - A New Component for Sequential Model-Based Hyperparameter Optimization},
	year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-319-23525-7_7}}

@inproceedings{pinto2016towards,
	author = {F{\'a}bio Pinto and C. Soares and Jo{\~a}o Mendes-Moreira},
	doi = {10.1007/978-3-319-31753-3_18},
	isbn = {978-3-319-31752-6},
	month = {04},
	pages = {215-226},
	title = {Towards Automatic Generation of Metafeatures},
	volume = {9651},
	year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-319-31753-3_18}}

@inproceedings{bardenet2013hyper,
	abstract = {Hyperparameter learning has traditionally been a manual task because of the limited
	number of trials. Today's computing infrastructures allow bigger evaluation budgets,
	thus opening the way for algorithmic approaches. Recently, surrogate-based optimization
	was successfully applied to hyperparameter learning for deep belief networks and to
	WEKA classifiers. The methods combined brute force computational power with model
	building about the behavior of the error function in the hyperparameter space, and
	they could significantly improve on manual hyperparameter tuning. What may make experienced
	practitioners even better at hyperparameter optimization is their ability to generalize
	across similar learning problems. In this paper, we propose a generic method to incorporate
	knowledge from previous experiments when simultaneously tuning a learning algorithm
	on new problems at hand. To this end, we combine surrogate-based ranking and optimization
	techniques for surrogate-based collaborative tuning (SCoT). We demonstrate SCoT in
	two experiments where it outperforms standard tuning techniques and single-problem
	surrogate-based optimization.},
	author = {Bardenet, R\'{e}mi and Brendel, M\'{a}ty\'{a}s and K\'{e}gl, Bal\'{a}zs and Sebag, Mich\`{e}le},
	booktitle = {Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28},
	location = {Atlanta, GA, USA},
	pages = {II--199--II--207},
	publisher = {JMLR.org},
	series = {ICML'13},
	title = {Collaborative Hyperparameter Tuning},
	year = {2013}}

@inproceedings{yogatama2014efficient,
	abstract = {We propose a fast and effective algorithm for automatic hyperparameter tuning that can generalize across datasets. Our method is an instance of sequential model-based optimization (SMBO) that transfers information by constructing a common response surface for all datasets, similar to Bardenet et al. (2013). The time complexity of reconstructing the response surface at every SMBO iteration in our method is linear in the number of trials (significantly less than previous work with comparable performance), allowing the method to realistically scale to many more datasets. Specifically, we use deviations from the per-dataset mean as the response values. We empirically show the superiority of our method on a large number of synthetic and real-world datasets for tuning hyperparameters of logistic regression and ensembles of classifiers.},
	address = {Reykjavik, Iceland},
	author = {Yogatama, Dani and Mann, Gideon},
	booktitle = {Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics},
	editor = {Kaski, Samuel and Corander, Jukka},
	month = {22--25 Apr},
	pages = {1077--1085},
	pdf = {http://proceedings.mlr.press/v33/yogatama14.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {{Efficient Transfer Learning Method for Automatic Hyperparameter Tuning}},
	url = {https://proceedings.mlr.press/v33/yogatama14.html},
	volume = {33},
	year = {2014},
	Bdsk-Url-1 = {https://proceedings.mlr.press/v33/yogatama14.html}}

@inproceedings{schilling2015hyp,
	author = {Schilling, Nicolas and Wistuba, Martin and Drumond, Lucas and Schmidt-Thieme, Lars},
	booktitle = {Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
	organization = {Springer},
	pages = {87--103},
	title = {Hyperparameter optimization with factorized multilayer perceptrons},
	year = {2015}}

@article{witsuba2018scalable,
	author = {Wistuba, Martin and Schilling, Nicolas and Schmidt-Thieme, Lars},
	doi = {10.1007/s10994-017-5684-y},
	journal = {Machine Learning},
	month = {01},
	title = {Scalable Gaussian process-based transfer surrogates for hyperparameter optimization},
	volume = {107},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10994-017-5684-y}}

@misc{activmetal,
	author = {Sun-Hosoya, Lisheng and Guyon, Isabelle and Sebag, Mich{\`e}le},
	hal_id = {hal-01931262},
	hal_version = {v1},
	howpublished = {{IAL 2018 workshop, ECML PKDD}},
	month = Sep,
	note = {Poster},
	pdf = {https://hal.archives-ouvertes.fr/hal-01931262/file/ACTIVMETAL.pdf},
	title = {{ActivMetaL: Algorithm Recommendation with Active Meta Learning}},
	url = {https://hal.archives-ouvertes.fr/hal-01931262},
	year = {2018},
	Bdsk-Url-1 = {https://hal.archives-ouvertes.fr/hal-01931262}}

@article{hospedales2021metalearning,
	author = {Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},
	doi = {10.1109/TPAMI.2021.3079209},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	month = {05},
	pages = {1-1},
	title = {Meta-Learning in Neural Networks: A Survey},
	volume = {PP},
	year = {2021},
	Bdsk-Url-1 = {https://doi.org/10.1109/TPAMI.2021.3079209}}

@article{lemke2013metalearning,
	author = {Lemke, Christiane and Budka, Marcin and Gabrys, Bogdan},
	doi = {10.1007/s10462-013-9406-y},
	journal = {Artificial Intelligence Review},
	month = {06},
	title = {Metalearning: a survey of trends and technologies},
	volume = {DOI: 10.1007/s10462-013-9406-y},
	year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10462-013-9406-y}}

@article{vilalta2001perspective,
	author = {Vilalta, Ricardo and Drissi, Youssef},
	doi = {10.1023/A:1019956318069},
	journal = {Artificial Intelligence Review},
	month = {09},
	title = {A Perspective View And Survey Of Meta-Learning},
	volume = {18},
	year = {2001},
	Bdsk-Url-1 = {https://doi.org/10.1023/A:1019956318069}}

@inproceedings{giraud2008metalearning,
	author = {Giraud-Carrier, Christophe},
	booktitle = {Tutorial at the 7th international conference on machine learning and applications (ICMLA), San Diego, California, USA},
	title = {Metalearning-a tutorial},
	year = {2008}}

@book{bradzil2009metalearning,
	author = {Brazdil, Pavel and Giraud-Carrier, Christophe and Soares, Carlos and Vilalta, Ricardo},
	doi = {10.1007/978-3-540-73263-1},
	isbn = {978-3-540-73262-4},
	journal = {Metalearning: Applications to Data Mining, Cognitive Technologies. ISBN 978-3-540-73262-4. Springer Berlin Heidelberg, 2009},
	month = {01},
	title = {Metalearning - Applications to Data Mining.},
	year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-540-73263-1}}

@phdthesis{vanschoren2010understanding,
	author = {Vanschoren, Joaquin},
	month = {05},
	title = {Understanding Machine Learning Performance with Experiment Databases},
	year = {2010}}

@techreport{wolpert1995no,
	author = {Wolpert, David H and Macready, William G and others},
	institution = {Technical Report SFI-TR-95-02-010, Santa Fe Institute},
	title = {No free lunch theorems for search},
	year = {1995}}

@misc{bischl2021hyperparameter,
	archiveprefix = {arXiv},
	author = {Bernd Bischl and Martin Binder and Michel Lang and Tobias Pielok and Jakob Richter and Stefan Coors and Janek Thomas and Theresa Ullmann and Marc Becker and Anne-Laure Boulesteix and Difan Deng and Marius Lindauer},
	eprint = {2107.05847},
	primaryclass = {stat.ML},
	title = {Hyperparameter Optimization: Foundations, Algorithms, Best Practices and Open Challenges},
	year = {2021}}

@article{scikit-learn,
	author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	journal = {Journal of Machine Learning Research},
	pages = {2825--2830},
	title = {Scikit-learn: Machine Learning in {P}ython},
	volume = {12},
	year = {2011}}

@inproceedings{wu2021frugal,
	author = {Wu, Qingyun and Wang, Chi and Huang, Silu},
	booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
	pages = {10347--10354},
	title = {Frugal optimization for cost-related hyperparameters},
	volume = {35},
	year = {2021}}

@misc{wu2019practical,
	archiveprefix = {arXiv},
	author = {Jian Wu and Saul Toscano-Palmerin and Peter I. Frazier and Andrew Gordon Wilson},
	eprint = {1903.04703},
	primaryclass = {cs.LG},
	title = {Practical Multi-fidelity Bayesian Optimization for Hyperparameter Tuning},
	year = {2019}}

@misc{vanschoren2018metalearning,
	archiveprefix = {arXiv},
	author = {Joaquin Vanschoren},
	eprint = {1810.03548},
	primaryclass = {cs.LG},
	title = {Meta-Learning: A Survey},
	year = {2018}}

@inproceedings{fuerer2015initializing,
	abstract = {Model selection and hyperparameter optimization is crucial in applying machine learning
	to a novel dataset. Recently, a sub-community of machine learning has focused on solving
	this problem with Sequential Model-based Bayesian Optimization (SMBO), demonstrating
	substantial successes in many applications. However, for computationally expensive
	algorithms the overhead of hyperparameter optimization can still be prohibitive. In
	this paper we mimic a strategy human domain experts use: speed up optimization by
	starting from promising configurations that performed well on similar datasets. The
	resulting initialization technique integrates naturally into the generic SMBO framework
	and can be trivially applied to any SMBO method. To validate our approach, we perform
	extensive experiments with two established SMBO frameworks (Spearmint and SMAC) with
	complementary strengths; optimizing two machine learning frameworks on 57 datasets.
	Our initialization procedure yields mild improvements for low-dimensional hyperparameter
	optimization and substantially improves the state of the art for the more complex
	combined algorithm selection and hyperparameter optimization problem.},
	author = {Feurer, Matthias and Springenberg, Jost Tobias and Hutter, Frank},
	booktitle = {Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence},
	isbn = {0262511290},
	location = {Austin, Texas},
	numpages = {8},
	pages = {1128--1135},
	publisher = {AAAI Press},
	series = {AAAI'15},
	title = {Initializing Bayesian Hyperparameter Optimization via Meta-Learning},
	year = {2015}}

@article{atomic,
	author = {Moniz, Nuno and Cerqueira, Vitor},
	doi = {10.1016/j.eswa.2021.115011},
	journal = {Expert Systems with Applications},
	month = {04},
	pages = {115011},
	title = {Automated Imbalanced Classification via Meta-learning},
	volume = {178},
	year = {2021},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.eswa.2021.115011}}

@article{Feurer2020AutoSklearn2T,
	author = {Matthias Feurer and Katharina Eggensperger and S. Falkner and M. Lindauer and F. Hutter},
	journal = {ArXiv},
	title = {Auto-Sklearn 2.0: The Next Generation},
	volume = {abs/2007.04074},
	year = {2020}}

@article{borkowski1994optimal,
	author = {Borkowski, John and Pukelsheim, Friedrich},
	doi = {10.2307/1270234},
	journal = {Technometrics},
	month = {05},
	pages = {214},
	title = {Optimal Design of Experiments},
	volume = {36},
	year = {1994},
	Bdsk-Url-1 = {https://doi.org/10.2307/1270234}}

@inbook{makar2011teaching,
	author = {Makar, Katie and Fielding-Wells, Jill},
	doi = {10.1007/978-94-007-1131-0_33},
	isbn = {978-94-007-1130-3},
	month = {06},
	pages = {347-358},
	title = {Teaching Teachers to Teach Statistical Investigations},
	year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-94-007-1131-0_33}}

@inproceedings{falkner2018bohb,
	author = {Falkner, Stefan and Klein, Aaron and Hutter, Frank},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {1437--1446},
	title = {BOHB: Robust and efficient hyperparameter optimization at scale},
	year = {2018}}

@article{li2018hyperband,
	abstract = {Performance of machine learning algorithms depends critically on identifying a good
	set of hyperparameters. While recent approaches use Bayesian optimization to adaptively
	select configurations, we focus on speeding up random search through adaptive resource
	allocation and early-stopping. We formulate hyperparameter optimization as a pure-exploration
	nonstochastic infinite-armed bandit problem where a predefined resource like iterations,
	data samples, or features is allocated to randomly sampled configurations. We introduce
	a novel algorithm, Hyperband, for this framework and analyze its theoretical properties,
	providing several desirable guarantees. Furthermore, we compare Hyperband with popular
	Bayesian optimization methods on a suite of hyperparameter optimization problems.
	We observe that Hyperband can provide over an order-of-magnitude speedup over our
	competitor set on a variety of deep-learning and kernel-based learning problems.},
	author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
	issn = {1532-4435},
	issue_date = {January 2017},
	journal = {J. Mach. Learn. Res.},
	keywords = {hyperparameter optimization, deep learning, model selection, online optimization, infinite-armed bandits},
	month = jan,
	number = {1},
	numpages = {52},
	pages = {6765--6816},
	publisher = {JMLR.org},
	title = {Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization},
	volume = {18},
	year = {2017}}

@inproceedings{hutter2011sequential,
	author = {Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
	booktitle = {International conference on learning and intelligent optimization},
	organization = {Springer},
	pages = {507--523},
	title = {Sequential model-based optimization for general algorithm configuration},
	year = {2011}}

@article{wolpert1992stacked,
	author = {Wolpert, David},
	doi = {10.1016/S0893-6080(05)80023-1},
	journal = {Neural Networks},
	month = {12},
	pages = {241-259},
	title = {Stacked Generalization},
	volume = {5},
	year = {1992},
	Bdsk-Url-1 = {https://doi.org/10.1016/S0893-6080(05)80023-1}}

@article{breiman1996stacked,
	address = {USA},
	author = {Breiman, Leo},
	doi = {10.1023/A:1018046112532},
	issn = {0885-6125},
	issue_date = {July 1996},
	journal = {Mach. Learn.},
	keywords = {combinations, trees, stacking, non-negativity, subset regression},
	month = jul,
	number = {1},
	numpages = {16},
	pages = {49--64},
	publisher = {Kluwer Academic Publishers},
	title = {Stacked Regressions},
	url = {https://doi.org/10.1023/A:1018046112532},
	volume = {24},
	year = {1996},
	Bdsk-Url-1 = {https://doi.org/10.1023/A:1018046112532}}

@inproceedings{snoek2012practical,
	abstract = {The use of machine learning algorithms frequently involves careful tuning of learning
	parameters and model hyperparameters. Unfortunately, this tuning is often a "black
	art" requiring expert experience, rules of thumb, or sometimes brute-force search.
	There is therefore great appeal for automatic approaches that can optimize the performance
	of any given learning algorithm to the problem at hand. In this work, we consider
	this problem through the framework of Bayesian optimization, in which a learning algorithm's
	generalization performance is modeled as a sample from a Gaussian process (GP). We
	show that certain choices for the nature of the GP, such as the type of kernel and
	the treatment of its hyperparameters, can play a crucial role in obtaining a good
	optimizer that can achieve expertlevel performance. We describe new algorithms that
	take into account the variable cost (duration) of learning algorithm experiments and
	that can leverage the presence of multiple cores for parallel experimentation. We
	show that these proposed algorithms improve on previous automatic procedures and can
	reach or surpass human expert-level optimization for many algorithms including latent
	Dirichlet allocation, structured SVMs and convolutional neural networks.},
	address = {Red Hook, NY, USA},
	author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
	booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 2},
	location = {Lake Tahoe, Nevada},
	numpages = {9},
	pages = {2951--2959},
	publisher = {Curran Associates Inc.},
	series = {NIPS'12},
	title = {Practical Bayesian Optimization of Machine Learning Algorithms},
	year = {2012}}

@inproceedings{maclaurin2015gradient,
	abstract = {Tuning hyperparameters of learning algorithms is hard because gradients are usually
	unavailable. We compute exact gradients of cross-validation performance with respect
	to all hyperparameters by chaining derivatives backwards through the entire training
	procedure. These gradients allow us to optimize thousands of hyperparameters, including
	step-size and momentum schedules, weight initialization distributions, richly parameterized
	regularization schemes, and neural network architectures. We compute hyperparameter
	gradients by exactly reversing the dynamics of stochastic gradient descent with momentum.},
	author = {Maclaurin, Dougal and Duvenaud, David and Adams, Ryan P.},
	booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
	location = {Lille, France},
	numpages = {10},
	pages = {2113--2122},
	publisher = {JMLR.org},
	series = {ICML'15},
	title = {Gradient-Based Hyperparameter Optimization through Reversible Learning},
	year = {2015}}

@inproceedings{weimar2007cofirank,
	abstract = {In this paper, we consider collaborative filtering as a ranking problem. We present
	a method which uses Maximum Margin Matrix Factorization and optimizes ranking instead
	of rating. We employ structured output prediction to optimize directly for ranking
	scores. Experimental results show that our method gives very good ranking scores and
	scales well on collaborative filtering tasks.},
	address = {Red Hook, NY, USA},
	author = {Weimer, Markus and Karatzoglou, Alexandros and Le, Quoc Viet and Smola, Alex},
	booktitle = {Proceedings of the 20th International Conference on Neural Information Processing Systems},
	isbn = {9781605603520},
	location = {Vancouver, British Columbia, Canada},
	numpages = {8},
	pages = {1593--1600},
	publisher = {Curran Associates Inc.},
	series = {NIPS'07},
	title = {CofiRank Maximum Margin Matrix Factorization for Collaborative Ranking},
	year = {2007}}

@techreport{burges2010from,
	abstract = {LambdaMART is the boosted tree version of LambdaRank, which is based on RankNet. RankNet, LambdaRank, and LambdaMART have proven to be very successful algorithms for solving real world ranking problems: for example an ensemble of LambdaMART rankers won Track 1 of the 2010 Yahoo! Learning To Rank Challenge. The details of these algorithms are spread across several papers and reports, and so here we give a self-contained, detailed and complete description of them.},
	author = {Burges, Chris J.C.},
	month = {June},
	number = {MSR-TR-2010-82},
	title = {From RankNet to LambdaRank to LambdaMART: An Overview},
	url = {https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/},
	year = {2010},
	Bdsk-Url-1 = {https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/}}

@article{rankml,
	author = {Doron Laadan and Roman Vainshtein and Yarden Curiel and Gilad Katz and Lior Rokach},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1911-00108.bib},
	eprint = {1911.00108},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Sat, 23 Jan 2021 01:20:08 +0100},
	title = {RankML: a Meta Learning-Based Approach for Pre-Ranking Machine Learning Pipelines},
	url = {http://arxiv.org/abs/1911.00108},
	volume = {abs/1911.00108},
	year = {2019},
	Bdsk-Url-1 = {http://arxiv.org/abs/1911.00108}}

@inproceedings{pge2015,
	author = {Hyun-Tae Kim and Chang Wook Ahn},
	booktitle = {Proceedings in Adaptation, Learning and Optimization},
	doi = {10.1007/978-3-319-13356-0_1},
	pages = {1--12},
	publisher = {Springer International Publishing},
	title = {A New Grammatical Evolution Based on Probabilistic Context-free Grammar},
	url = {https://doi.org/10.1007/978-3-319-13356-0_1},
	year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-319-13356-0_1}}

@inproceedings{castiello2005metadata,
	abstract = {Common inductive learning strategies offer the tools for knowledge acquisition, but possess some inherent limitations due to the use of fixed bias during the learning process. To overcome limitations of such base-learning approaches, a novel research trend is oriented to explore the potentialities of meta-learning, which is oriented to the development of mechanisms based on a dynamical search of bias. This could lead to an improvement of the base-learner performance on specific learning tasks, by profiting of the accumulated past experience. As a significant set of I/O data is needed for efficient base-learning, appropriate meta-data characterization is of crucial importance for useful meta-learning. In order to characterize meta-data, firstly a collection of meta-features discriminating among different base-level tasks should be identified. This paper focuses on the characterization of meta-data, through an analysis of meta-features that can capture the properties of specific tasks to be solved at base level. This kind of approach represents a first step toward the development of a meta-learning system, capable of suggesting the proper bias for base-learning different specific task domains.},
	address = {Berlin, Heidelberg},
	author = {Castiello, Ciro and Castellano, Giovanna and Fanelli, Anna Maria},
	booktitle = {Modeling Decisions for Artificial Intelligence},
	editor = {Torra, Vicen{\c{c}} and Narukawa, Yasuo and Miyamoto, Sadaaki},
	isbn = {978-3-540-31883-5},
	pages = {457--468},
	publisher = {Springer Berlin Heidelberg},
	title = {Meta-data: Characterization of Input Features for Meta-learning},
	year = {2005}}
	
@article{vanschoren2014openml,
author = {Vanschoren, Joaquin and van Rijn, Jan N. and Bischl, Bernd and Torgo, Luis},
title = {OpenML: Networked Science in Machine Learning},
year = {2014},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1931-0145},
url = {https://doi.org/10.1145/2641190.2641198},
doi = {10.1145/2641190.2641198},
abstract = {Many sciences have made significant breakthroughs by adopting online tools that help
organize, structure and mine information that is too detailed to be printed in journals.
In this paper, we introduce OpenML, a place for machine learning researchers to share
and organize data in fine detail, so that they can work more effectively, be more
visible, and collaborate with others to tackle harder problems. We discuss how OpenML
relates to other examples of networked science and what benefits it brings for machine
learning research, individual scientists, as well as students and practitioners.},
journal = {SIGKDD Explor. Newsl.},
month = jun,
pages = {49–60},
numpages = {12}
}

@article{feurer2019openmlpy,
  author    = {Matthias Feurer and
               Jan N. van Rijn and
               Arlind Kadra and
               Pieter Gijsbers and
               Neeratyoy Mallik and
               Sahithya Ravi and
               Andreas M{\"{u}}ller and
               Joaquin Vanschoren and
               Frank Hutter},
  title     = {OpenML-Python: an extensible Python {API} for OpenML},
  journal   = {CoRR},
  volume    = {abs/1911.02490},
  year      = {2019},
  url       = {http://arxiv.org/abs/1911.02490},
  eprinttype = {arXiv},
  eprint    = {1911.02490},
  timestamp = {Mon, 11 Nov 2019 18:38:09 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1911-02490.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{paszke2019pytorch,
  author    = {Adam Paszke and
               Sam Gross and
               Francisco Massa and
               Adam Lerer and
               James Bradbury and
               Gregory Chanan and
               Trevor Killeen and
               Zeming Lin and
               Natalia Gimelshein and
               Luca Antiga and
               Alban Desmaison and
               Andreas K{\"{o}}pf and
               Edward Yang and
               Zach DeVito and
               Martin Raison and
               Alykhan Tejani and
               Sasank Chilamkurthy and
               Benoit Steiner and
               Lu Fang and
               Junjie Bai and
               Soumith Chintala},
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  journal   = {CoRR},
  volume    = {abs/1912.01703},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.01703},
  eprinttype = {arXiv},
  eprint    = {1912.01703},
  timestamp = {Thu, 02 Jan 2020 18:08:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-01703.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{chollet2015keras,
  title={Keras},
  author={Chollet, Francois and others},
  year={2015},
  publisher={GitHub},
  url={https://github.com/fchollet/keras},
}

@book{bird2009natural,
  title={Natural language processing with Python: analyzing text with the natural language toolkit},
  author={Bird, Steven and Klein, Ewan and Loper, Edward},
  year={2009},
  publisher={O'Reilly Media, Inc.}
}

@inproceedings{khosrovian2008gensim,
author = {Khosrovian, Keyvan and Pfahl, Dietmar and Garousi, Vahid},
year = {2008},
month = {05},
pages = {294-306},
title = {GENSIM 2.0: A Customizable Process Simulation Model for Software Process Evaluation},
volume = {5007},
isbn = {978-3-540-79587-2},
doi = {10.1007/978-3-540-79588-9_26}
}

@phdthesis{sun2014MetaLearningAT,
  title={Meta-Learning and the Full Model Selection Problem},
  author={Quan Sun},
  year={2014},
 school={University of Waikato, Hamilton, New Zealand}
}

@article{costa2005weighted,
author = {Costa, Joaquim and Soares, Carlos},
year = {2005},
month = {11},
pages = {515 - 529},
title = {A weighted rank measure of correlation},
volume = {47},
journal = {Australian \& New Zealand Journal of Statistics},
doi = {10.1111/j.1467-842X.2005.00413.x}
}

@phdthesis{soares2004learning,
  title={Learning Ranking of Learning Algorithms},
  author={Carlos Soares},
  year={2004},
 school={Department of Computer Science, University of Porto}
}

@inproceedings{soares2000measures,
author="Soares, Carlos
and Brazdil, Pavel
and Costa, Joaquim",
editor="Kiers, Henk A. L.
and Rasson, Jean-Paul
and Groenen, Patrick J. F.
and Schader, Martin",
title="Measures to Evaluate Rankings of Classification Algorithms",
booktitle="Data Analysis, Classification, and Related Methods",
year="2000",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="119--124",
abstract="Due to the wide variety of algorithms for supervised classification originating from several research areas, selecting one of them to apply on a given problem is not a trivial task. Recently several methods have been developed to create rankings of classification algorithms based on their previous performance. Therefore, it is necessary to develop techniques to evaluate and compare those methods. We present three measures to evaluate rankings of classification algorithms, give examples of their use and discuss their characteristics.",
isbn="978-3-642-59789-3"
}

@inproceedings{gomes2012combining,
  title={Combining meta-learning and optimization algorithms for parameter selection},
  author={Gomes, T and Miranda, P and Prud{\^e}ncio, R and Soares, C and Carvalho, A},
  booktitle={5 th PLANNING TO LEARN WORKSHOP WS28 AT ECAI 2012},
  pages={6},
  year={2012},
  organization={Citeseer}
}

@article{xgboost,
  author    = {Tianqi Chen and
               Carlos Guestrin},
  title     = {XGBoost: {A} Scalable Tree Boosting System},
  journal   = {CoRR},
  volume    = {abs/1603.02754},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.02754},
  eprinttype = {arXiv},
  eprint    = {1603.02754},
  timestamp = {Mon, 13 Aug 2018 16:47:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChenG16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{miller2017quant,
  title={The quant crunch: How the demand for data science skills is disrupting the job market},
  author={Miller, Steven and Hughes, Debbie},
  journal={Burning Glass Technologies},
  year={2017},
  url={https://www.ibm.com/downloads/cas/3RL3VXGA}
}

@inproceedings{drozdal2020trust,
author = {Drozdal, Jaimie and Weisz, Justin and Wang, Dakuo and Dass, Gaurav and Yao, Bingsheng and Zhao, Changruo and Muller, Michael and Ju, Lin and Su, Hui},
title = {Trust in AutoML: Exploring Information Needs for Establishing Trust in Automated Machine Learning Systems},
year = {2020},
isbn = {9781450371186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377325.3377501},
doi = {10.1145/3377325.3377501},
abstract = {We explore trust in a relatively new area of data science: Automated Machine Learning
(AutoML). In AutoML, AI methods are used to generate and optimize machine learning
models by automatically engineering features, selecting models, and optimizing hyperparameters.
In this paper, we seek to understand what kinds of information influence data scientists'
trust in the models produced by AutoML? We operationalize trust as a willingness to
deploy a model produced using automated methods. We report results from three studies
- qualitative interviews, a controlled experiment, and a card-sorting task - to understand
the information needs of data scientists for establishing trust in AutoML systems.
We find that including transparency features in an AutoML tool increased user trust
and understandability in the tool; and out of all proposed features, model performance
metrics and visualizations are the most important information to data scientists when
establishing their trust with an AutoML tool.},
booktitle = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
pages = {297–307},
numpages = {11},
keywords = {automated machine learning, automated data science, AutoDS, trust, AutoML, automated artificial intelligence, AutoAI},
location = {Cagliari, Italy},
series = {IUI '20}
}

@article{wang2019humanai,
author = {Wang, Dakuo and Weisz, Justin D. and Muller, Michael and Ram, Parikshit and Geyer, Werner and Dugan, Casey and Tausczik, Yla and Samulowitz, Horst and Gray, Alexander},
title = {Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
url = {https://doi.org/10.1145/3359313},
doi = {10.1145/3359313},
abstract = {The rapid advancement of artificial intelligence (AI) is changing our lives in many
ways. One application domain is data science. New techniques in automating the creation
of AI, known as AutoAI or AutoML, aim to automate the work practices of data scientists.
AutoAI systems are capable of autonomously ingesting and pre-processing data, engineering
new features, and creating and scoring models based on a target objectives (e.g. accuracy
or run-time efficiency). Though not yet widely adopted, we are interested in understanding
how AutoAI will impact the practice of data science. We conducted interviews with
20 data scientists who work at a large, multinational technology company and practice
data science in various business settings. Our goal is to understand their current
work practices and how these practices might change with AutoAI. Reactions were mixed:
while informants expressed concerns about the trend of automating their jobs, they
also strongly felt it was inevitable. Despite these concerns, they remained optimistic
about their future job security due to a view that the future of data science work
will be a collaboration between humans and AI systems, in which both automation and
human expertise are indispensable.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {211},
numpages = {24},
keywords = {autoai, human-in-the-loop ai, data science, domain experts, human-centered ai, automl, ai design ai, machine learning, data scientist, human-ai collaboration, future of work, automation}
}

@inbook{crisan2021fits,
author = {Crisan, Anamaria and Fiore-Gartland, Brittany},
title = {Fits and Starts: Enterprise Use of AutoML and the Role of Humans in the Loop},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445775},
abstract = { AutoML systems can speed up routine data science work and make machine learning available
to those without expertise in statistics and computer science. These systems have
gained traction in enterprise settings where pools of skilled data workers are limited.
In this study, we conduct interviews with 29 individuals from organizations of different
sizes to characterize how they currently use, or intend to use, AutoML systems in
their data science work. Our investigation also captures how data visualization is
used in conjunction with AutoML systems. Our findings identify three usage scenarios
for AutoML that resulted in a framework summarizing the level of automation desired
by data workers with different levels of expertise. We surfaced the tension between
speed and human oversight and found that data visualization can do a poor job balancing
the two. Our findings have implications for the design and implementation of human-in-the-loop
visual analytics approaches.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {601},
numpages = {15}
}

@article{lee2019AHP,
  title={A Human-in-the-loop Perspective on AutoML: Milestones and the Road Ahead},
  author={Doris Jung Lin Lee and Stephen Macke and Doris Xin and Angela Lee and Silu Huang and Aditya G. Parameswaran},
  journal={IEEE Data Eng. Bull.},
  year={2019},
  volume={42},
  url={http: //sites.computer.org/debull/A19june/p59.pdf},
  pages={59-70}
}

@article{zoller2019surver,
  author    = {Marc{-}Andr{\'{e}} Z{\"{o}}ller and
               Marco F. Huber},
  title     = {Survey on Automated Machine Learning},
  journal   = {CoRR},
  volume    = {abs/1904.12054},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.12054},
  eprinttype = {arXiv},
  eprint    = {1904.12054},
  timestamp = {Thu, 02 May 2019 15:13:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-12054.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{hutter2011SequentialMO,
  title={Sequential Model-Based Optimization for General Algorithm Configuration},
  author={Frank Hutter and Holger H. Hoos and Kevin Leyton-Brown},
  booktitle={LION},
  year={2011}
}

@article{peng2020comprehensive,
  author    = {Huimin Peng},
  title     = {A Comprehensive Overview and Survey of Recent Advances in Meta-Learning},
  journal   = {CoRR},
  volume    = {abs/2004.11149},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.11149},
  eprinttype = {arXiv},
  eprint    = {2004.11149},
  timestamp = {Sat, 23 Jan 2021 01:11:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-11149.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{biggs1985role,
author = {Biggs, J. B.},
title = {The Role of Metalearning in Study Processes},
journal = {British Journal of Educational Psychology},
volume = {55},
number = {3},
pages = {185-212},
doi = {https://doi.org/10.1111/j.2044-8279.1985.tb02625.x},
url = {https://bpspsychub.onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8279.1985.tb02625.x},
eprint = {https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-8279.1985.tb02625.x},
abstract = {Summary. Effective learning under institutional conditions requires, first, that students are aware of task demands and of their intentions of how, or even whether, to meet those demands, and, second, that they assess realistically, and exert control over, their own cognitive resources. The fulfilment of such conditions involves a sophisticated kind of metacognition, here called metalearning. The present paper describes a series of studies that collectively explicate the development and role of metalearning in the learning and study processes of secondary and tertiary students. Ability patterns, locus of control, variety and quality of certain non-school experiences, and extent and kind of motivation all seem to be involved in the development of metalearning capability. A model of student learning is then described, in which personal and situational factors are linked to performance by three main approaches to learning: deep, achieving, and surface. These approaches involve varying degrees of metalearning and lead to qualitatively different learning outcomes. An intervention study on improving student learning is described that tests important aspects of the model, and further implications for teaching and research are suggested.},
year = {1985}
}

@article{hey2020machinelearning,
	author = {Hey, Tony and Butler, Keith and Jackson, Sam and Thiyagalingam, Jeyarajan},
	year = {2020},
	month = {03},
	pages = {20190054},
	title = {Machine learning and big scientific data},
	volume = {378},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	doi = {10.1098/rsta.2019.0054}
}

@book{hutter2019autmlbook,
	author = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
	title = {Automated Machine Learning: Methods, Systems, Challenges},
	year = {2019},
	isbn = {3030053172},
	publisher = {Springer Publishing Company, Incorporated},
	edition = {1st},
	abstract = {This open access book presents the first comprehensive overview of general methods
	in Automated Machine Learning (AutoML), collects descriptions of existing systems
	based on these methods, and discusses the first series of international challenges
	of AutoML systems. The recent success of commercial ML applications and the rapid
	growth of the field has created a high demand for off-the-shelf ML methods that can
	be used easily and without expert knowledge. However, many of the recent machine learning
	successes crucially rely on human experts, who manually select appropriate ML architectures
	(deep learning architectures or more traditional ML workflows) and their hyperparameters.
	To overcome this problem, the field of AutoML targets a progressive automation of
	machine learning, based on principles from optimization and machine learning itself.
	This book serves as a point of entry into this quickly-developing field for researchers
	and advanced students alike, as well as providing a reference for practitioners aiming
	to use AutoML in their work.}
}

@article{xin2019automl,
	author    = {Xin He and
	Kaiyong Zhao and
	Xiaowen Chu},
	title     = {AutoML: {A} Survey of the State-of-the-Art},
	journal   = {CoRR},
	volume    = {abs/1908.00709},
	year      = {2019},
	url       = {http://arxiv.org/abs/1908.00709},
	eprinttype = {arXiv},
	eprint    = {1908.00709},
	timestamp = {Thu, 28 Oct 2021 13:52:50 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1908-00709.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dyrmishi2019decision,
	author = {Dyrmishi, Salijona and El Shawi, Radwa and Sakr, Sherif},
	year = {2019},
	month = {11},
	pages = {97-106},
	title = {A Decision Support Framework for AutoML Systems: A Meta-Learning Approach},
	doi = {10.1109/ICDMW.2019.00025}
}

@article{radwa2019automated,
	author    = {Radwa El Shawi and
	Mohamed Maher and
	Sherif Sakr},
	title     = {Automated Machine Learning: State-of-The-Art and Open Challenges},
	journal   = {CoRR},
	volume    = {abs/1906.02287},
	year      = {2019},
	url       = {http://arxiv.org/abs/1906.02287},
	eprinttype = {arXiv},
	eprint    = {1906.02287},
	timestamp = {Thu, 13 Jun 2019 13:36:00 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1906-02287.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Xin,
	place = {Country unknown/Code not available}, 
	title = {Whither AutoML? Understanding the Role of Automation in Machine Learning Workflows}, 
	url = {https://par.nsf.gov/biblio/10216118}, 
	abstractNote = {}, 
	year = {2021},
	journal = {Human factors in computing systems}, 
	author = {Doris Xin, Eva Yiwei}
}