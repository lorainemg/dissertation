@article{baker2016designing,
	title={Designing neural network architectures using reinforcement learning},
	author={Baker, Bowen and Gupta, Otkrist and Naik, Nikhil and Raskar, Ramesh},
	journal={arXiv preprint arXiv:1611.02167},
	year={2016}
}

@inproceedings{bergstra2013hyperopt,
	title={Hyperopt: A python library for optimizing the hyperparameters of machine learning algorithms},
	author={Bergstra, James and Yamins, Dan and Cox, David D and others},
	booktitle={Proceedings of the 12th Python in science conference},
	volume={13},
	pages={20},
	year={2013},
	organization={Citeseer}
}

@article{bischl2016aslib,
	title={Aslib: A benchmark library for algorithm selection},
	author={Bischl, Bernd and Kerschke, Pascal and Kotthoff, Lars and Lindauer, Marius and Malitsky, Yuri and Fr{\'e}chette, Alexandre and Hoos, Holger and Hutter, Frank and Leyton-Brown, Kevin and Tierney, Kevin and others},
	journal={Artificial Intelligence},
	volume={237},
	pages={41--58},
	year={2016},
	publisher={Elsevier}
}


@inproceedings{chen2018autostacker,
	title={Autostacker: A compositional evolutionary learning system},
	author={Chen, Boyuan and Wu, Harvey and Mo, Warren and Chattopadhyay, Ishanu and Lipson, Hod},
	booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
	pages={402--409},
	year={2018}
}

@inproceedings{de2017recipe,
	title={RECIPE: a grammar-based framework for automatically evolving classification pipelines},
	author={de S{\'a}, Alex GC and Pinto, Walter Jos{\'e} GS and Oliveira, Luiz Otavio VB and Pappa, Gisele L},
	booktitle={European Conference on Genetic Programming},
	pages={246--261},
	year={2017},
	organization={Springer}
}

@inproceedings{de2018automated,
	title={Automated selection and configuration of multi-label classification algorithms with grammar-based genetic programming},
	author={de S{\'a}, Alex GC and Freitas, Alex A and Pappa, Gisele L},
	booktitle={International Conference on Parallel Problem Solving from Nature},
	pages={308--320},
	year={2018},
	organization={Springer}
}

@article{elshawi2019automated,
	title={Automated machine learning: State-of-the-art and open challenges},
	author={Elshawi, Radwa and Maher, Mohamed and Sakr, Sherif},
	journal={arXiv preprint arXiv:1906.02287},
	year={2019}
}

@inproceedings{jin2019auto,
	title={Auto-keras: An efficient neural architecture search system},
	author={Jin, Haifeng and Song, Qingquan and Hu, Xia},
	booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
	pages={1946--1956},
	year={2019}
}

@inproceedings{komer2014hyperopt,
	title={Hyperopt-sklearn: automatic hyperparameter configuration for scikit-learn},
	author={Komer, Brent and Bergstra, James and Eliasmith, Chris},
	booktitle={ICML workshop on AutoML},
	volume={9},
	pages={50},
	year={2014},
	organization={Citeseer}
}

@inproceedings{maher2019smartml,
	title={Smartml: A meta learning-based framework for automated selection and hyperparameter tuning for machine learning algorithms},
	author={Maher, Mohamed and Sakr, Sherif},
	booktitle={EDBT: 22nd International Conference on Extending Database Technology},
	year={2019}
}

@inproceedings{mendoza2016towards,
	title={Towards automatically-tuned neural networks},
	author={Mendoza, Hector and Klein, Aaron and Feurer, Matthias and Springenberg, Jost Tobias and Hutter, Frank},
	booktitle={Workshop on Automatic Machine Learning},
	pages={58--65},
	year={2016},
	organization={PMLR}
}

@article{mohr2018ml,
	title={ML-Plan: Automated machine learning via hierarchical planning},
	author={Mohr, Felix and Wever, Marcel and H{\"u}llermeier, Eyke},
	journal={Machine Learning},
	volume={107},
	number={8},
	pages={1495--1515},
	year={2018},
	publisher={Springer}
}

@inproceedings{fusi2018advances,
	author = {Fusi, Nicolo and Sheth, Rishit and Elibol, Melih},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Probabilistic Matrix Factorization for Automated Machine Learning},
	url = {https://proceedings.neurips.cc/paper/2018/file/b59a51a3c0bf9c5228fde841714f523a-Paper.pdf},
	volume = {31},
	year = {2018}
}


@article{yang2018oboe,
	author    = {Chengrun Yang and
	Yuji Akimoto and
	Dae Won Kim and
	Madeleine Udell},
	title     = {{OBOE:} Collaborative Filtering for AutoML Initialization},
	journal   = {CoRR},
	volume    = {abs/1808.03233},
	year      = {2018},
	url       = {http://arxiv.org/abs/1808.03233},
	archivePrefix = {arXiv},
	eprint    = {1808.03233},
	timestamp = {Sun, 02 Sep 2018 15:01:57 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1808-03233.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{olson2016evaluation,
	title={Evaluation of a tree-based pipeline optimization tool for automating data science},
	author={Olson, Randal S and Bartley, Nathan and Urbanowicz, Ryan J and Moore, Jason H},
	booktitle={Proceedings of the genetic and evolutionary computation conference 2016},
	pages={485--492},
	year={2016}
}

@inproceedings{pham2018efficient,
	title={Efficient neural architecture search via parameters sharing},
	author={Pham, Hieu and Guan, Melody and Zoph, Barret and Le, Quoc and Dean, Jeff},
	booktitle={International Conference on Machine Learning},
	pages={4095--4104},
	year={2018},
	organization={PMLR}
}

@article{rakotoarison2019automated,
	title={Automated machine learning with monte-carlo tree search},
	author={Rakotoarison, Herilalaina and Schoenauer, Marc and Sebag, Mich{\`e}le},
	journal={arXiv preprint arXiv:1906.00170},
	year={2019}
}

@inproceedings{evans2020adaptive,
	title={An adaptive and near parameter-free evolutionary computation approach towards true automation in automl},
	author={Evans, Benjamin and Xue, Bing and Zhang, Mengjie},
	booktitle={2020 IEEE Congress on Evolutionary Computation (CEC)},
	pages={1--8},
	year={2020},
	organization={IEEE}
}

@inproceedings{shang2019democratizing,
	title={Democratizing data science through interactive curation of ml pipelines},
	author={Shang, Zeyuan and Zgraggen, Emanuel and Buratti, Benedetto and Kossmann, Ferdinand and Eichmann, Philipp and Chung, Yeounoh and Binnig, Carsten and Upfal, Eli and Kraska, Tim},
	booktitle={Proceedings of the 2019 International Conference on Management of Data},
	pages={1171--1188},
	year={2019}
}

@inproceedings{thornton2013auto,
	title={Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms},
	author={Thornton, Chris and Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
	booktitle={Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining},
	pages={847--855},
	year={2013}
}

@article{wang2018rafiki,
	title={Rafiki: Machine learning as an analytics service system},
	author={Wang, Wei and Wang, Sheng and Gao, Jinyang and Zhang, Meihui and Chen, Gang and Ng, Teck Khim and Ooi, Beng Chin},
	journal={arXiv preprint arXiv:1804.06087},
	year={2018}
}


@article{wang2021flaml,
	title={FLAML: A Fast and Lightweight AutoML Library},
	author={Wang, Chi and Wu, Qingyun and Weimer, Markus and Zhu, Erkang},
	journal={Proceedings of Machine Learning and Systems},
	volume={3},
	year={2021}
}

@article{zoph2016neural,
	title={Neural architecture search with reinforcement learning},
	author={Zoph, Barret and Le, Quoc V},
	journal={arXiv preprint arXiv:1611.01578},
	year={2016}
}

@inproceedings{swearingen2017atm,
	title={ATM: A distributed, collaborative, scalable system for automated machine learning},
	author={Swearingen, Thomas and Drevo, Will and Cyphers, Bennett and Cuesta-Infante, Alfredo and Ross, Arun and Veeramachaneni, Kalyan},
	booktitle={2017 IEEE International Conference on Big Data (Big Data)},
	pages={151--162},
	year={2017},
	organization={IEEE}
}

@inproceedings{yang2020automl,
	title={Automl pipeline selection: Efficiently navigating the combinatorial space},
	author={Yang, Chengrun and Fan, Jicong and Wu, Ziyang and Udell, Madeleine},
	booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
	pages={1446--1456},
	year={2020}
}

@article{zimmer2021auto,
	title={Auto-Pytorch: Multi-Fidelity MetaLearning for Efficient and Robust AutoDL},
	author={Zimmer, Lucas and Lindauer, Marius and Hutter, Frank},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	year={2021},
	publisher={IEEE}
}

@inproceedings{drori2018alphad3m,
	title={AlphaD3M: Machine learning pipeline synthesis},
	author={Drori, Iddo and Krishnamurthy, Yamuna and Rampin, Remi and Louren{\c{c}}o, Raoni and One, Jorge and Cho, Kyunghyun and Silva, Claudio and Freire, Juliana},
	booktitle={AutoML Workshop at ICML},
	year={2018}
}

@inproceedings{fuerer2015efficient,
	author = {Feurer, Matthias and Klein, Aaron and Eggensperger, Katharina and Springenberg, Jost and Blum, Manuel and Hutter, Frank},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Efficient and Robust Automated Machine Learning},
	url = {https://proceedings.neurips.cc/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf},
	volume = {28},
	year = {2015}
}

@Inbook{olson2019tpot,
	author="Olson, Randal S.
	and Moore, Jason H.",
	editor="Hutter, Frank
	and Kotthoff, Lars
	and Vanschoren, Joaquin",
	title="TPOT: A Tree-Based Pipeline Optimization Tool for Automating Machine Learning",
	bookTitle="Automated Machine Learning: Methods, Systems, Challenges",
	year="2019",
	publisher="Springer International Publishing",
	address="Cham",
	pages="151--160",
	abstract="As data science becomes increasingly mainstream, there will be an ever-growing demand for data science tools that are more accessible, flexible, and scalable. In response to this demand, automated machine learning (AutoML) researchers have begun building systems that automate the process of designing and optimizing machine learning pipelines. In this chapter we present TPOT v0.3, an open source genetic programming-based AutoML system that optimizes a series of feature preprocessors and machine learning models with the goal of maximizing classification accuracy on a supervised classification task. We benchmark TPOT on a series of 150 supervised classification tasks and find that it significantly outperforms a basic machine learning analysis in 21 of them, while experiencing minimal degradation in accuracy on 4 of the benchmarks---all without any domain knowledge nor human input. As such, genetic programming-based AutoML systems show considerable promise in the AutoML domain.",
	isbn="978-3-030-05318-5",
	doi="10.1007/978-3-030-05318-5_8",
	url="https://doi.org/10.1007/978-3-030-05318-5_8"
}

@inproceedings{chen2018autostacker,
	author = {Chen, Boyuan and Wu, Harvey and Mo, Warren and Chattopadhyay, Ishanu and Lipson, Hod},
	title = {Autostacker: A Compositional Evolutionary Learning System},
	year = {2018},
	isbn = {9781450356183},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3205455.3205586},
	doi = {10.1145/3205455.3205586},
	abstract = {In this work, an automatic machine learning (AutoML) modeling architecture called
	Autostacker is introduced. Autostacker combines an innovative hierarchical stacking
	architecture and an evolutionary algorithm (EA) to perform efficient parameter search
	without the need for prior domain knowledge about the data or feature preprocessing.
	Using EA, Autostacker quickly evolves candidate pipelines with high predictive accuracy.
	These pipelines can be used in their given form, or serve as a starting point for
	further augmentation and refinement by human experts. Autostacker finds innovative
	machine learning model combinations and structures, rather than selecting a single
	model and optimizing its hyperparameters. When its performance on fifteen datasets
	is compared with that of other AutoML systems, Autostacker produces superior or competitive
	results in terms of both test accuracy and time cost.},
	booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
	pages = {402–409},
	numpages = {8},
	keywords = {autoML, evolutionary machine learning, machine learning},
	location = {Kyoto, Japan},
	series = {GECCO '18}
}

@inproceedings{real2020automl,
	title={Automl-zero: Evolving machine learning algorithms from scratch},
	author={Real, Esteban and Liang, Chen and So, David and Le, Quoc},
	booktitle={International Conference on Machine Learning},
	pages={8007--8019},
	year={2020},
	organization={PMLR}
}

@article{NSGA-II,
	author = {Deb, K. and Pratap, A. and Agarwal, S. and Meyarivan, T.},
	title = {A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II},
	year = {2002},
	issue_date = {April 2002},
	publisher = {IEEE Press},
	volume = {6},
	number = {2},
	issn = {1089-778X},
	url = {https://doi.org/10.1109/4235.996017},
	doi = {10.1109/4235.996017},
	abstract = {Multi-objective evolutionary algorithms (MOEAs) that use non-dominated sorting and
	sharing have been criticized mainly for: (1) their O(MN3) computational complexity
	(where M is the number of objectives and N is the population size); (2) their non-elitism
	approach; and (3) the need to specify a sharing parameter. In this paper, we suggest
	a non-dominated sorting-based MOEA, called NSGA-II (Non-dominated Sorting Genetic
	Algorithm II), which alleviates all of the above three difficulties. Specifically,
	a fast non-dominated sorting approach with O(MN2) computational complexity is presented.
	Also, a selection operator is presented that creates a mating pool by combining the
	parent and offspring populations and selecting the best N solutions (with respect
	to fitness and spread). Simulation results on difficult test problems show that NSGA-II
	is able, for most problems, to find a much better spread of solutions and better convergence
	near the true Pareto-optimal front compared to the Pareto-archived evolution strategy
	and the strength-Pareto evolutionary algorithm - two other elitist MOEAs that pay
	special attention to creating a diverse Pareto-optimal front. Moreover, we modify
	the definition of dominance in order to solve constrained multi-objective problems
	efficiently. Simulation results of the constrained NSGA-II on a number of test problems,
	including a five-objective, seven-constraint nonlinear problem, are compared with
	another constrained multi-objective optimizer, and the much better performance of
	NSGA-II is observed},
	journal = {Trans. Evol. Comp},
	month = apr,
	pages = {182–197},
	numpages = {16}
}

@article{alphazero,
	author    = {David Silver and
	Thomas Hubert and
	Julian Schrittwieser and
	Ioannis Antonoglou and
	Matthew Lai and
	Arthur Guez and
	Marc Lanctot and
	Laurent Sifre and
	Dharshan Kumaran and
	Thore Graepel and
	Timothy P. Lillicrap and
	Karen Simonyan and
	Demis Hassabis},
	title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
	Learning Algorithm},
	journal   = {CoRR},
	volume    = {abs/1712.01815},
	year      = {2017},
	url       = {http://arxiv.org/abs/1712.01815},
	eprinttype = {arXiv},
	eprint    = {1712.01815},
	timestamp = {Mon, 13 Aug 2018 16:46:01 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1712-01815.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{OracleAutoML,
	author = {Yakovlev, Anatoly and Moghadam, Hesam Fathi and Moharrer, Ali and Cai, Jingxiao and Chavoshi, Nikan and Varadarajan, Venkatanathan and Agrawal, Sandeep R. and Idicula, Sam and Karnagel, Tomas and Jinturkar, Sanjay and Agarwal, Nipun},
	title = {Oracle AutoML: A Fast and Predictive AutoML Pipeline},
	year = {2020},
	issue_date = {August 2020},
	publisher = {VLDB Endowment},
	volume = {13},
	number = {12},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3415478.3415542},
	doi = {10.14778/3415478.3415542},
	abstract = {Machine learning (ML) is at the forefront of the rising popularity of data-driven
	software applications. The resulting rapid proliferation of ML technology, explosive
	data growth, and shortage of data science expertise have caused the industry to face
	increasingly challenging demands to keep up with fast-paced develop-and-deploy model
	lifecycles. Recent academic and industrial research efforts have started to address
	this problem through automated machine learning (AutoML) pipelines and have focused
	on model performance as the first-order design objective. We present Oracle AutoML,
	a novel iteration-free AutoML pipeline designed to not only provide accurate models,
	but also in a shorter runtime. We are able to achieve these objectives by eliminating
	the need to continuously iterate over various pipeline configurations. In our feed-forward
	approach, each pipeline stage makes decisions based on metalearned proxy models that
	can predict candidate pipeline configuration performances before building the full
	final model. Our approach, which builds and tunes only the best candidate pipeline,
	achieves better scores at a fraction of the time compared to state-of-the-art open
	source AutoML tools, such as H2O and Auto-sklearn. This makes Oracle AutoML a prime
	candidate for addressing current industry challenges.},
	journal = {Proc. VLDB Endow.},
	month = aug,
	pages = {3166–3180},
	numpages = {15}
}

@article{sun2013pairwise,
	title={Pairwise meta-rules for better meta-learning-based algorithm ranking},
	author={Sun, Quan and Pfahringer, Bernhard},
	journal={Machine learning},
	volume={93},
	number={1},
	pages={141--161},
	year={2013},
	publisher={Springer}
}

@inproceedings{Pinto2016TowardsAG,
	title={Towards Automatic Generation of Metafeatures},
	author={F{\'a}bio Pinto and C. Soares and Jo{\~a}o Mendes-Moreira},
	booktitle={PAKDD},
	year={2016}
}

@inproceedings{pinto2014framework,
	author = {Pinto, F\'{a}bio and Soares, Carlos and Mendes-Moreira, Jo\~{a}o},
	title = {A Framework to Decompose and Develop Metafeatures},
	year = {2014},
	isbn = {16130073},
	publisher = {CEUR-WS.org},
	address = {Aachen, DEU},
	abstract = {This paper proposes a framework to decompose and develop metafeatures for Metalearning
	(MtL) problems. Several metafeatures (also known as data characteristics) are proposed
	in the literature for a wide range of problems. Since MtL applicability is very general
	but problem dependent, researchers focus on generating specific and yet informative
	metafeatures for each problem. This process is carried without any sort of conceptual
	framework. We believe that such framework would open new horizons on the development
	of metafeatures and also aid the process of understanding the metafeatures already
	proposed in the state-of-the-art. We propose a framework with the aim of fill that
	gap and we show its applicability in a scenario of algorithm recommendation for regression
	problems.},
	booktitle = {Proceedings of the 2014 International Conference on Meta-Learning and Algorithm Selection - Volume 1201},
	pages = {32–36},
	numpages = {5},
	location = {Prague, Czech Republic},
	series = {MLAS'14}
}

@article{bilalli2017predictive,
	author = {Bilalli, Besim and Abell\'{o}, Alberto and Aluja-Banet, Tom\'{\i}s},
	title = {On the Predictive Power of Meta-Features in OpenML},
	year = {2017},
	issue_date = {20 12 2017},
	publisher = {Walter de Gruyter &amp; Co.},
	address = {USA},
	volume = {27},
	number = {4},
	issn = {1641-876X},
	url = {https://doi.org/10.1515/amcs-2017-0048},
	doi = {10.1515/amcs-2017-0048},
	abstract = {Abstract The demand for performing data analysis is steadily rising. As a consequence,
	people of different profiles i.e., nonexperienced users have started to analyze their
	data. However, this is challenging for them. A key step that poses difficulties and
	determines the success of the analysis is data mining model/algorithm selection problem.
	Meta-learning is a technique used for assisting non-expert users in this step. The
	effectiveness of meta-learning is, however, largely dependent on the description/characterization
	of datasets i.e., meta-features used for meta-learning. There is a need for improving
	the effectiveness of meta-learning by identifying and designing more predictive meta-features.
	In this work, we use a method from exploratory factor analysis to study the predictive
	power of different meta-features collected in OpenML, which is a collaborative machine
	learning platform that is designed to store and organize meta-data about datasets,
	data mining algorithms, models and their evaluations. We first use the method to extract
	latent features, which are abstract concepts that group together meta-features with
	common characteristics. Then, we study and visualize the relationship of the latent
	features with three different performance measures of four classification algorithms
	on hundreds of datasets available in OpenML, and we select the latent features with
	the highest predictive power. Finally, we use the selected latent features to perform
	meta-learning and we show that our method improves the meta-learning process. Furthermore,
	we design an easy to use application for retrieving different meta-data from OpenML
	as the biggest source of data in this domain.},
	journal = {Int. J. Appl. Math. Comput. Sci.},
	month = dec,
	pages = {697–712},
	numpages = {16},
	keywords = {feature extraction, meta-learning, feature selection}
}

@article{Rivolli2018TowardsRE,
	title={Towards Reproducible Empirical Research in Meta-Learning},
	author={Adriano Rivolli and L. P. F. Garcia and Carlos Soares and J. Vanschoren and A. Carvalho},
	journal={ArXiv},
	year={2018},
	volume={abs/1808.10406}
}

@inproceedings{santos2004selection,
	author = {Santos, Patrícia and Ludermir, Teresa and Prudêncio, Ricardo},
	year = {2004},
	month = {01},
	pages = {366-371},
	title = {Selection of Time Series Forecasting Models based on Performance Information},
	journal = {Proceedings - HIS'04: 4th International Conference on Hybrid Intelligent Systems},
	doi = {10.1109/ICHIS.2004.86}
}

@article{bradzil2003ranking,
	author = {Brazdil, Pavel and Soares, Carlos and Costa, Joaquim},
	year = {2003},
	month = {03},
	pages = {251-277},
	title = {Ranking Learning Algorithms: Using IBL and Meta-Learning on Accuracy and Time Results},
	volume = {50},
	journal = {Machine Learning},
	doi = {10.1023/A:1021713901879}
}

@inproceedings{todorovski2002ranking,
	author = {Todorovski, Ljupco and Blockeel, Hendrik and Džeroski, Sašo},
	year = {2002},
	month = {08},
	pages = {444-455},
	title = {Ranking with Predictive Clustering Trees},
	volume = {2430},
	isbn = {978-3-540-44036-9},
	doi = {10.1007/3-540-36755-1_37}
}

@article{tomaz2020oblique,
	author    = {Tomaz Stepisnik and
	Dragi Kocev},
	title     = {Oblique Predictive Clustering Trees},
	journal   = {CoRR},
	volume    = {abs/2007.13617},
	year      = {2020},
	url       = {https://arxiv.org/abs/2007.13617},
	eprinttype = {arXiv},
	eprint    = {2007.13617},
	timestamp = {Wed, 29 Jul 2020 15:36:39 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2007-13617.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{guerra2008predicting,
	author = {Guerra, Silvio and Prudencio, Ricardo and Ludermir, Teresa},
	year = {2008},
	month = {09},
	pages = {523-532},
	title = {Predicting the Performance of Learning Algorithms Using Support Vector Machines as Meta-regressors},
	volume = {5163},
	isbn = {978-3-540-87535-2},
	doi = {10.1007/978-3-540-87536-9_54}
}

@article{reif2012automatic,
	author = {Reif, Matthias and Shafait, Faisal and Goldstein, Markus and Breuel, Thomas and Dengel, Andreas},
	year = {2012},
	month = {02},
	pages = {},
	title = {Automatic Classifier Selection for Non-Experts},
	volume = {17},
	journal = {Pattern Analysis and Applications},
	doi = {10.1007/s10044-012-0280-z}
}

@inproceedings{ridd2014using,
	author = {Ridd, Parker and Giraud-Carrier, Christophe},
	title = {Using Metalearning to Predict When Parameter Optimization is Likely to Improve Classification Accuracy},
	year = {2014},
	isbn = {16130073},
	publisher = {CEUR-WS.org},
	address = {Aachen, DEU},
	abstract = {Work on metalearning for algorithm selection has often been criticized because it
	mostly considers only the default parameter settings of the candidate base learning
	algorithms. Many have indeed argued that the choice of parameter values can have a
	significant impact on accuracy. Yet little empirical evidence exists to provide definitive
	support for that argument. Recent experiments do suggest that parameter optimization
	may indeed have an impact. However, the distribution of performance differences has
	a long tail, suggesting that in most cases parameter optimization has little effect
	on accuracy. In this paper, we revisit some of these results and use metalearning
	to characterize the situations when parameter optimization is likely to cause a significant
	increase in accuracy. In so doing, we show that 1) a relatively simple and efficient
	landmarker carries significant predictive power, and 2) metalearning for algorithm
	selection should be effected in two phases, the first in which one determines whether
	parameter optimization is likely to increase accuracy, and the second in which algorithm
	selection actually takes place.},
	booktitle = {Proceedings of the 2014 International Conference on Meta-Learning and Algorithm Selection - Volume 1201},
	pages = {18–23},
	numpages = {6},
	location = {Prague, Czech Republic},
	series = {MLAS'14}
}

@inproceedings{sanders2017informing,
	author = {Sanders, Samantha and Giraud-Carrier, Christophe},
	year = {2017},
	month = {11},
	pages = {1051-1056},
	title = {Informing the Use of Hyperparameter Optimization Through Metalearning},
	doi = {10.1109/ICDM.2017.137}
}

@inproceedings{leite2017selecting,
	author = {Leite, Rui and Brazdil, Pavel and Vanschoren, Joaquin},
	year = {2012},
	month = {07},
	pages = {117-131},
	title = {Selecting Classification Algorithms with Active Testing},
	volume = {7376},
	isbn = {978-3-642-31536-7},
	journal = {Lecture Notes in Computer Science},
	doi = {10.1007/978-3-642-31537-4_10}
}


@article{abdulrahman2018speeding,
	author = {Abdulrahman, Salisu Mamman and Brazdil, Pavel and Rijn, Jan N. and Vanschoren, Joaquin},
	title = {Speeding up Algorithm Selection Using Average Ranking and Active Testing by Introducing Runtime},
	year = {2018},
	issue_date = {January   2018},
	publisher = {Kluwer Academic Publishers},
	address = {USA},
	volume = {107},
	number = {1},
	issn = {0885-6125},
	url = {https://doi.org/10.1007/s10994-017-5687-8},
	doi = {10.1007/s10994-017-5687-8},
	abstract = {Algorithm selection methods can be speeded-up substantially by incorporating multi-objective
	measures that give preference to algorithms that are both promising and fast to evaluate.
	In this paper, we introduce such a measure, A3R, and incorporate it into two algorithm
	selection techniques: average ranking and active testing. Average ranking combines
	algorithm rankings observed on prior datasets to identify the best algorithms for
	a new dataset. The aim of the second method is to iteratively select algorithms to
	be tested on the new dataset, learning from each new evaluation to intelligently select
	the next best candidate. We show how both methods can be upgraded to incorporate a
	multi-objective measure A3R that combines accuracy and runtime. It is necessary to
	establish the correct balance between accuracy and runtime, as otherwise time will
	be wasted by conducting less informative tests. The correct balance can be set by
	an appropriate parameter setting within function A3R that trades off accuracy and
	runtime. Our results demonstrate that the upgraded versions of Average Ranking and
	Active Testing lead to much better mean interval loss values than their accuracy-based
	counterparts.},
	journal = {Mach. Learn.},
	month = jan,
	pages = {79–108},
	numpages = {30},
	keywords = {Loss curves, Meta-learning, Average ranking, Algorithm selection, Mean interval loss, Ranking of algorithms, Active testing}
}

@inproceedings{witsuba2015learning,
	author={Wistuba, Martin and Schilling, Nicolas and Schmidt-Thieme, Lars},
	booktitle={2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)}, 
	title={Learning hyperparameter optimization initializations}, 
	year={2015},
	volume={},
	number={},
	pages={1-10},
	doi={10.1109/DSAA.2015.7344817}
}


@article{abdulrahman2014measures,
	author = {Abdulrahman, Salisu and Brazdil, Pavel},
	year = {2014},
	month = {01},
	pages = {49-50},
	title = {Measures for combining accuracy and time for meta-learning},
	volume = {1201},
	journal = {CEUR Workshop Proceedings}
}

@inproceedings{rijn2018hyp,
	author = {van Rijn, Jan N. and Hutter, Frank},
	title = {Hyperparameter Importance Across Datasets},
	year = {2018},
	isbn = {9781450355520},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3219819.3220058},
	doi = {10.1145/3219819.3220058},
	abstract = {With the advent of automated machine learning, automated hyperparameter optimization
	methods are by now routinely used in data mining. However, this progress is not yet
	matched by equal progress on automatic analyses that yield information beyond performance-optimizing
	hyperparameter settings. In this work, we aim to answer the following two questions:
	Given an algorithm, what are generally its most important hyperparameters, and what
	are typically good values for these? We present methodology and a framework to answer
	these questions based on meta-learning across many datasets. We apply this methodology
	using the experimental meta-data available on OpenML to determine the most important
	hyperparameters of support vector machines, random forests and Adaboost, and to infer
	priors for all their hyperparameters. The results, obtained fully automatically, provide
	a quantitative basis to focus efforts in both manual algorithm design and in automated
	hyperparameter optimization. The conducted experiments confirm that the hyperparameters
	selected by the proposed method are indeed the most important ones and that the obtained
	priors also lead to statistically significant improvements in hyperparameter optimization.},
	booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery},
	pages = {2367–2376},
	numpages = {10},
	keywords = {meta-learning, hyperparameter importance, hyperparameter optimization},
	location = {London, United Kingdom},
	series = {KDD '18}
}


@inproceedings{witsuba2015hyper,
	author = {Wistuba, Martin and Schilling, Nicolas and Schmidt-Thieme, Lars},
	year = {2015},
	month = {09},
	pages = {104-119},
	title = {Hyperparameter Search Space Pruning - A New Component for Sequential Model-Based Hyperparameter Optimization},
	doi = {10.1007/978-3-319-23525-7_7}
}

@inproceedings{pinto2016towards,
	author = {F{\'a}bio Pinto and C. Soares and Jo{\~a}o Mendes-Moreira},
	year = {2016},
	month = {04},
	pages = {215-226},
	title = {Towards Automatic Generation of Metafeatures},
	volume = {9651},
	isbn = {978-3-319-31752-6},
	doi = {10.1007/978-3-319-31753-3_18}
}

@inproceedings{bardenet2013hyper,
	author = {Bardenet, R\'{e}mi and Brendel, M\'{a}ty\'{a}s and K\'{e}gl, Bal\'{a}zs and Sebag, Mich\`{e}le},
	title = {Collaborative Hyperparameter Tuning},
	year = {2013},
	publisher = {JMLR.org},
	abstract = {Hyperparameter learning has traditionally been a manual task because of the limited
	number of trials. Today's computing infrastructures allow bigger evaluation budgets,
	thus opening the way for algorithmic approaches. Recently, surrogate-based optimization
	was successfully applied to hyperparameter learning for deep belief networks and to
	WEKA classifiers. The methods combined brute force computational power with model
	building about the behavior of the error function in the hyperparameter space, and
	they could significantly improve on manual hyperparameter tuning. What may make experienced
	practitioners even better at hyperparameter optimization is their ability to generalize
	across similar learning problems. In this paper, we propose a generic method to incorporate
	knowledge from previous experiments when simultaneously tuning a learning algorithm
	on new problems at hand. To this end, we combine surrogate-based ranking and optimization
	techniques for surrogate-based collaborative tuning (SCoT). We demonstrate SCoT in
	two experiments where it outperforms standard tuning techniques and single-problem
	surrogate-based optimization.},
	booktitle = {Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28},
	pages = {II–199–II–207},
	location = {Atlanta, GA, USA},
	series = {ICML'13}
}


@InProceedings{yogatama2014efficient,
	title = 	 {{Efficient Transfer Learning Method for Automatic Hyperparameter Tuning}},
	author = 	 {Yogatama, Dani and Mann, Gideon},
	booktitle = 	 {Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics},
	pages = 	 {1077--1085},
	year = 	 {2014},
	editor = 	 {Kaski, Samuel and Corander, Jukka},
	volume = 	 {33},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Reykjavik, Iceland},
	month = 	 {22--25 Apr},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v33/yogatama14.pdf},
	url = 	 {https://proceedings.mlr.press/v33/yogatama14.html},
	abstract = 	 {We propose a fast and effective algorithm for automatic hyperparameter tuning that can generalize across datasets. Our method is an instance of sequential model-based optimization (SMBO) that transfers information by constructing a common response surface for all datasets, similar to Bardenet et al. (2013). The time complexity of reconstructing the response surface at every SMBO iteration in our method is linear in the number of trials (significantly less than previous work with comparable performance), allowing the method to realistically scale to many more datasets. Specifically, we use deviations from the per-dataset mean as the response values. We empirically show the superiority of our method on a large number of synthetic and real-world datasets for tuning hyperparameters of logistic regression and ensembles of classifiers.}
}

@inproceedings{schilling2015hyp,
	title={Hyperparameter optimization with factorized multilayer perceptrons},
	author={Schilling, Nicolas and Wistuba, Martin and Drumond, Lucas and Schmidt-Thieme, Lars},
	booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
	pages={87--103},
	year={2015},
	organization={Springer}
}

@article{witsuba2018scalable,
	author = {Wistuba, Martin and Schilling, Nicolas and Schmidt-Thieme, Lars},
	year = {2018},
	month = {01},
	pages = {},
	title = {Scalable Gaussian process-based transfer surrogates for hyperparameter optimization},
	volume = {107},
	journal = {Machine Learning},
	doi = {10.1007/s10994-017-5684-y}
}

@misc{activmetal,
	TITLE = {{ActivMetaL: Algorithm Recommendation with Active Meta Learning}},
	AUTHOR = {Sun-Hosoya, Lisheng and Guyon, Isabelle and Sebag, Mich{\`e}le},
	URL = {https://hal.archives-ouvertes.fr/hal-01931262},
	NOTE = {Poster},
	HOWPUBLISHED = {{IAL 2018 workshop, ECML PKDD}},
	YEAR = {2018},
	MONTH = Sep,
	PDF = {https://hal.archives-ouvertes.fr/hal-01931262/file/ACTIVMETAL.pdf},
	HAL_ID = {hal-01931262},
	HAL_VERSION = {v1},
}
